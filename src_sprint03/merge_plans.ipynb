{"cells":[{"cell_type":"markdown","metadata":{"id":"lXwr4xlrrxzn"},"source":["# DEPENDÊNCIAS"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dQn8UGuErvIu","executionInfo":{"status":"ok","timestamp":1751029480731,"user_tz":180,"elapsed":3216,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import joblib\n","import warnings\n","\n","\n","from google.colab import drive\n","from itertools import product\n","from sklearn.base import BaseEstimator, clone\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import Lasso\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from xgboost import XGBRegressor"]},{"cell_type":"markdown","metadata":{"id":"m9o3_k8Ir7Wu"},"source":["# FUNÇÕES"]},{"cell_type":"markdown","source":["## Constantes"],"metadata":{"id":"N3Cu4HzOdJqC"}},{"cell_type":"code","source":["_PARAMS = \"params\"\n","_CROSS_VAL = \"cv\"\n","_TEST = \"test\""],"metadata":{"id":"ZBlcvK0rdI2t","executionInfo":{"status":"ok","timestamp":1751029480749,"user_tz":180,"elapsed":16,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Utilitário"],"metadata":{"id":"1irKhamJdCLj"}},{"cell_type":"code","source":["def dict_flatten(dictionary: dict, fields_to_flatten: list[str]) -> dict:\n","    \"\"\"\n","    Desestrutura os campos selecionados de um dicionário, retornando apenas os atributos desejados.\n","\n","    :param dictionary: Dicionário original que contém os campos a serem desestruturados.\n","    :param fields_to_flatten: Lista de nomes dos campos que devem ser desestruturados (flatten).\n","\n","    :return: Novo dicionário contendo apenas os atributos dos campos selecionados, combinados em um nível.\n","    \"\"\"\n","    dict_flat = dict()\n","\n","    for field in fields_to_flatten:\n","        value = dictionary.get(field)\n","        if isinstance(value, dict):\n","            dict_flat.update(value)\n","\n","    return dict_flat\n","\n","def dict_to_flat_df(dictionary: dict, fields_to_flatten: list[str], key_name: str = \"key\") -> pd.DataFrame:\n","    \"\"\"\n","    Converte um dicionário com estrutura aninhada em um DataFrame tabular, desestruturando\n","    apenas os campos especificados.\n","\n","    :param dictionary: Dicionário em que cada chave representa um identificador único e cada valor é um dicionário com possíveis campos aninhados.\n","    :param fields_to_flatten: Lista de nomes de campos a serem desestruturados. Cada um deve\n","                               corresponder a uma chave cujo valor é um dicionário.\n","    :param key_name: Nome da coluna que armazenará os identificadores do dicionário original.\n","                     Padrão é \"key\".\n","\n","    :return: DataFrame com uma coluna para os identificadores e colunas adicionais contendo os\n","             atributos resultantes da desestruturação dos campos selecionados.\n","    \"\"\"\n","    rows = list()\n","\n","    for identifier, nested_dict in dictionary.items():\n","        dict_flat = dict_flatten(nested_dict, fields_to_flatten)\n","        dict_flat[key_name] = identifier\n","        rows.append(dict_flat)\n","\n","    df = pd.DataFrame(rows)\n","    df = df[[key_name] + [col for col in df.columns if col != key_name]]  # Coloca a chave primeiro\n","    return df"],"metadata":{"id":"Savo2yLhdBR2","executionInfo":{"status":"ok","timestamp":1751029480796,"user_tz":180,"elapsed":2,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"zh4OEIX2rpqE","executionInfo":{"status":"ok","timestamp":1751029485361,"user_tz":180,"elapsed":49,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}}},"outputs":[],"source":["def dict_deserialize(path: str) -> dict:\n","    \"\"\"\n","    Desserializa (carrega) um dicionário Python a partir de um arquivo .pkl.\n","\n","    :param path: Caminho completo do arquivo a ser carregado.\n","                 Deve terminar com a extensão '.pkl' (ex: 'dict_cases.pkl').\n","    :return: Dicionário Python carregado a partir do arquivo.\n","    \"\"\"\n","    return joblib.load(path)\n","\n","def dict_serialize(dictionary: dict, path: str) -> None:\n","    \"\"\"\n","    Serializa (salva) um dicionário Python em um arquivo no formato .pkl.\n","\n","    :param dictionary: Dicionário a ser serializado.\n","    :param path: Caminho completo do arquivo de destino.\n","                 Deve terminar com a extensão '.pkl' (ex: 'dict_cases.pkl').\n","    \"\"\"\n","    joblib.dump(dictionary, path)\n","\n","def generate_sheet(dict_cases: dict, sheet_name: str, path: str) -> None:\n","    \"\"\"\n","    Gera uma planilha Excel (.xlsx) contendo os dados tabulares dos casos modelados.\n","\n","    :param dict_cases: Dicionário onde cada chave identifica um caso e o valor é um\n","                       dicionário com os dados do modelo, parâmetros e métricas.\n","    :param sheet_name: Nome da aba (sheet) que será criada no arquivo Excel.\n","    :param path: Caminho completo do arquivo .xlsx que será criado.\n","                 Deve terminar com a extensão '.xlsx' (ex: 'resultados.xlsx').\n","\n","    A função realiza o seguinte:\n","    - Achata os campos definidos em FLATTEN (campos dicionário), elevando-os ao primeiro nível.\n","    - Concatena os dados em um único DataFrame.\n","    - Escreve esse DataFrame em uma planilha Excel na aba especificada.\n","    \"\"\"\n","    FLATTEN = [_PARAMS, _CROSS_VAL, _TEST] # Campos a serem passados para o primeiro nível\n","    KEY_NAME = \"case\" # Nome do campo que armazenará o identificador dos casos\n","\n","    \"\"\"\n","    Achata campos que são dicionários, deixando todas as informações no primeiro\n","    nível. Em seguida, transforma em um DataFrame.\n","    \"\"\"\n","    df_final = dict_to_flat_df(dict_cases, FLATTEN, KEY_NAME)\n","\n","    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n","        df_final.to_excel(writer, sheet_name=sheet_name, index=False)"]},{"cell_type":"markdown","metadata":{"id":"mcMd333-sDeW"},"source":["# SETUP DO AMBIENTE"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1751029488051,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"},"user_tz":180},"id":"-fmtk-4UsCrT","outputId":"82193a7c-38f5-41f7-c1ba-898fb6f7b6da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","source":["# SETUP"],"metadata":{"id":"jJKOPM8yb3YK"}},{"cell_type":"code","source":["# Constantes simbólicas\n","PRE = \"pre_processing\"              # Pré-processamento\n","RF = \"random_forest\"                # Random Forest\n","XGB = \"xgboost\"                     # XGBoost\n","MLR = \"multiple_linear_regression\"  # Regressão Linear Múltipla\n","ALL = \"all\"                         # Todos os modelos considerados simultaneamente\n","\n","# Dicionário para armazenar os resultados\n","dict_cases = dict() # Armazena dicionários de casos\n","dict_df_cases = dict() # Armazena DataFrames de casos\n","\n","# SALVAMENTO\n","PATH_IN = \"/content/drive/MyDrive/07_per_shared/projCDat_25_1/src_sprint03/plans\"\n","PATH_OUT = \"/content/drive/MyDrive/07_per_shared/projCDat_25_1/src_sprint03/plans\""],"metadata":{"id":"davYOJaWbkAf","executionInfo":{"status":"ok","timestamp":1751029488945,"user_tz":180,"elapsed":4,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for key in [PRE, MLR, XGB]:\n","    dict_cases[key] = dict_deserialize(f\"{PATH_IN}/{key}.pkl\")\n","    dict_df_cases[key] = pd.DataFrame(dict_cases[key]).T\n","    generate_sheet(dict_cases[key], key, f\"{PATH_OUT}/{key}.xlsx\")\n","    print(f\"Planilha {key} gerada.\")"],"metadata":{"id":"wK6qKOq0cCWe","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1751029559483,"user_tz":180,"elapsed":68391,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"}},"outputId":"964bcb1c-daf8-4a31-fa11-d0dbfdcf044f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Planilha pre_processing gerada.\n","Planilha multiple_linear_regression gerada.\n"]},{"output_type":"error","ename":"EOFError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-8-489020807.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPRE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXGB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdict_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{PATH_IN}/{key}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdict_df_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgenerate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{PATH_OUT}/{key}.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Planilha {key} gerada.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-5-331977321.py\u001b[0m in \u001b[0;36mdict_deserialize\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDicionário\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mcarregado\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpartir\u001b[0m \u001b[0mdo\u001b[0m \u001b[0marquivo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdict_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;31m# it has been written with. Other arrays are coerced to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# native endianness of the host system.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 obj = _unpickle(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             warnings.warn(\n","\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mEOFError\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"sLD3B-KxrnLy"},"source":["# TESTES LEITURA DE PKL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOjovAdUrmlM"},"outputs":[],"source":["PATH_BASE = \"/content/drive/MyDrive/07_per_shared/projCDat_25_1/s\n","# for i, k in zip(range(1), dict_pre.keys()):\n","#     X = dict_pre[k][\"X\"]\n","#     y = dict_pre[k][\"y\"]\n","#     params = dict_pre[k][\"params\"]\n","\n","# display(X.head())\n","# display(y.head())\n","# display(y.describe())\n","# display(params)\n","\n","# # STATUS: OK!\n","# dict_mlr = dict_deserialize(f\"{PATH_BASE}/mlinreg.pkl\")\n","\n","# for i, k in zip(range(1), dict_mlr.keys()):\n","#     dict_models = dict_mlr[k][\"best_model\"]\n","#     dict_scores_cross_val = dict_mlr[k][\"cv\"]\n","#     dict_scores_test = dict_mlr[k][\"test\"]\n","\n","# print(dict_models)\n","\n","# plot_coefs(dict_models[\"r2_cv_best_model\"].coef_)"]},{"cell_type":"markdown","metadata":{"id":"6QXp_YULCiqA"},"source":["# Teste Resíduos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"executionInfo":{"elapsed":1005,"status":"ok","timestamp":1750605023127,"user":{"displayName":"Pedro Barizon","userId":"03135422818883286168"},"user_tz":180},"id":"4z6OIyubCiS6","outputId":"ca10683e-a09c-471b-98bc-a59be56d4797"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso(alpha=0.0001, random_state=42)\n","_Lasso_\n","FS_na_FE_na_OUT0_NORM0_PCA5_Lasso_ALPHA_0.0001_FIT_INTERCEPT_true_MAX_ITER_1000_RANDOM_STATE_42\n","FS_na_FE_na_OUT0_NORM0_PCA5\n","FS_na_FE_na_OUT0_NORM0_PCA5\n","FS_na_FE_na_OUT0_NORM0_PCA5\n","0.397371083721644\n"]},{"output_type":"display_data","data":{"text/plain":["527    1.082322e+06\n","359    5.006538e+04\n","447   -6.290061e+04\n","31     5.048390e+04\n","621   -3.176296e+05\n","           ...     \n","668   -1.906047e+05\n","239    2.370618e+04\n","312    9.607568e+04\n","211   -3.662560e+04\n","861    3.270442e+04\n","Name: que_area_queimada, Length: 308, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>que_area_queimada</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>527</th>\n","      <td>1.082322e+06</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>5.006538e+04</td>\n","    </tr>\n","    <tr>\n","      <th>447</th>\n","      <td>-6.290061e+04</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>5.048390e+04</td>\n","    </tr>\n","    <tr>\n","      <th>621</th>\n","      <td>-3.176296e+05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>668</th>\n","      <td>-1.906047e+05</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>2.370618e+04</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>9.607568e+04</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>-3.662560e+04</td>\n","    </tr>\n","    <tr>\n","      <th>861</th>\n","      <td>3.270442e+04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>308 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{}}],"source":["PATH_BASE = \"/content/drive/MyDrive/07_per_shared/projCDat_25_1/src_sprint03/plans\"\n","dict_mlr = dict_deserialize(f\"{PATH_BASE}/multiple_linear_regression.pkl\")\n","dict_pre = dict_deserialize(f\"{PATH_BASE}/pre_processing.pkl\")\n","\n","for i, k in zip(range(1), dict_mlr.keys()):\n","    dict_models = dict_mlr[k][\"best_model\"]\n","    dict_scores_cross_val = dict_mlr[k][\"cv\"]\n","    dict_scores_test = dict_mlr[k][\"test\"]\n","    r2_y_pred_test = dict_mlr[k][\"y_pred\"][\"r2_best_model_test_y_pred\"]\n","    # print(dict_mlr[k])\n","    model = dict_models[\"r2_cv_best_model\"]\n","    print(model)\n","    model_name = \"_\" + model.__class__.__name__ + \"_\"\n","    print(model_name)\n","    print(k)\n","\n","    k_pre = k.split(model_name)[0]\n","    print(k_pre)\n","    k_pre = k_pre\n","    print(k_pre)\n","\n","    print(k_pre)\n","\n","    X = dict_pre[k_pre]['X']\n","    y = dict_pre[k_pre]['y']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n","    # y_pred = model.predict(X_test)\n","    y_pred = r2_y_pred_test\n","\n","    residues = y_test - y_pred\n","    print(r2_score(y_test, y_pred))\n","    display(residues)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPDBIf4skaJddTvYDZPRlt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}